import re
from deep_translator import GoogleTranslator
import chardet
import os
import math
import json
from datetime import datetime, date
import multiprocessing
import shutil
import psutil
import time
from pathlib import Path

# Sabit deÄŸiÅŸkenler
DAILY_LIMIT = 200000  # Google Translate gÃ¼nlÃ¼k karakter limiti
RATE_LIMIT_DELAY = 1  # Ä°stekler arasÄ± bekleme sÃ¼resi (saniye)
TEMP_DIR = "temp"  # GeÃ§ici dosyalarÄ±n saklanacaÄŸÄ± ana klasÃ¶r
PARTS_DIR = os.path.join(TEMP_DIR, "parts")  # ParÃ§a dosyalarÄ± klasÃ¶rÃ¼
PROGRESS_DIR = os.path.join(TEMP_DIR, "progress")  # Ä°lerleme dosyalarÄ± klasÃ¶rÃ¼
STATS_DIR = os.path.join(TEMP_DIR, "stats")  # Ä°statistik dosyalarÄ± klasÃ¶rÃ¼

class TranslationStats:
    def __init__(self):
        self.stats_file = os.path.join(STATS_DIR, f"stats_{date.today()}.json")
        self._load_stats()

    def _load_stats(self):
        if os.path.exists(self.stats_file):
            with open(self.stats_file, 'r') as f:
                stats = json.load(f)
                self.chars_translated = stats.get('chars_translated', 0)
                self.last_request = stats.get('last_request', 0)
        else:
            self.chars_translated = 0
            self.last_request = 0
        
    def _save_stats(self):
        os.makedirs(STATS_DIR, exist_ok=True)
        with open(self.stats_file, 'w') as f:
            json.dump({
                'chars_translated': self.chars_translated,
                'last_request': self.last_request,
                'last_update': datetime.now().isoformat()
            }, f)

    def can_translate(self, text_length):
        # GÃ¼nlÃ¼k limit kontrolÃ¼
        if self.chars_translated + text_length > DAILY_LIMIT:
            return False
        
        # Rate limit kontrolÃ¼
        current_time = time.time()
        if current_time - self.last_request < RATE_LIMIT_DELAY:
            time.sleep(RATE_LIMIT_DELAY - (current_time - self.last_request))
        
        return True

    def update_stats(self, text_length):
        self.chars_translated += text_length
        self.last_request = time.time()
        self._save_stats()

    def get_remaining_limit(self):
        return DAILY_LIMIT - self.chars_translated

def detect_encoding(file_path):
    with open(file_path, 'rb') as file:
        raw_data = file.read()
        result = chardet.detect(raw_data)
        return result['encoding']

def translate_with_retry(translator, text, stats, max_retries=3):
    if not text.strip():
        return text

    text_length = len(text)
    if not stats.can_translate(text_length):
        remaining = stats.get_remaining_limit()
        print(f"âš ï¸ GÃ¼nlÃ¼k limit aÅŸÄ±lÄ±yor! Kalan karakter: {remaining:,}")
        return text

    for attempt in range(max_retries):
        try:
            translated = translator.translate(text=text)
            stats.update_stats(text_length)
            return translated
        except Exception as e:
            if attempt == max_retries - 1:
                print(f"Ã‡eviri baÅŸarÄ±sÄ±z: {str(e)}")
                return text
            print(f"Yeniden deneniyor... ({attempt + 1}/{max_retries})")
            time.sleep(RATE_LIMIT_DELAY * 2)

def save_progress(part_num, last_line, total_lines):
    progress_file = os.path.join(PROGRESS_DIR, f"progress_{part_num:03d}.json")
    os.makedirs(PROGRESS_DIR, exist_ok=True)
    with open(progress_file, 'w') as f:
        json.dump({
            'last_line': last_line,
            'total_lines': total_lines,
            'completed': last_line >= total_lines - 1,
            'timestamp': datetime.now().isoformat()
        }, f)

def load_progress(part_num):
    progress_file = os.path.join(PROGRESS_DIR, f"progress_{part_num:03d}.json")
    if os.path.exists(progress_file):
        with open(progress_file, 'r') as f:
            return json.load(f)
    return None

def get_optimal_process_count():
    cpu_count = psutil.cpu_count(logical=False)
    available_memory = psutil.virtual_memory().available / (1024 * 1024 * 1024)
    max_processes_by_memory = int(available_memory / 0.5)
    optimal_count = min(cpu_count, max_processes_by_memory)
    return max(1, min(optimal_count, 16))  # En fazla 16 paralel iÅŸlem

def process_file(input_file, part_num, start_line, end_line, file_encoding):
    translator = GoogleTranslator(source='de', target='tr')
    stats = TranslationStats()
    output_file = os.path.join(PARTS_DIR, f"part_{part_num:03d}.str")
    
    try:
        # Ä°lerleme kontrolÃ¼
        progress = load_progress(part_num)
        if progress and progress['completed']:
            print(f"ParÃ§a {part_num} zaten tamamlanmÄ±ÅŸ, atlanÄ±yor...")
            return True

        # Mevcut Ã§evrilmiÅŸ satÄ±rlarÄ± yÃ¼kle
        translated_lines = []
        if os.path.exists(output_file):
            with open(output_file, 'r', encoding=file_encoding) as f:
                translated_lines = f.readlines()

        with open(input_file, 'r', encoding=file_encoding) as f:
            all_lines = f.readlines()
            lines_to_process = all_lines[start_line:end_line]
            
        start_idx = len(translated_lines)
        total = len(lines_to_process)
        
        # Limit bilgisini gÃ¶ster
        remaining_limit = stats.get_remaining_limit()
        print(f"ParÃ§a {part_num} baÅŸlÄ±yor. Kalan gÃ¼nlÃ¼k limit: {remaining_limit:,} karakter")
        
        for i, line in enumerate(lines_to_process[start_idx:], start=start_idx):
            if i % 10 == 0:
                progress = (i/total*100)
                remaining_limit = stats.get_remaining_limit()
                print(f"ParÃ§a {part_num}: {progress:.1f}% tamamlandÄ± (Kalan limit: {remaining_limit:,})")
                
            match = re.match(r'(\S+)\s+"(.+)"', line.strip())
            if match:
                key, value = match.groups()
                translated_text = translate_with_retry(translator, value, stats)
                translated_line = f'{key} "{translated_text}"\n'
            else:
                translated_line = line
                
            translated_lines.append(translated_line)
            
            # Her 10 satÄ±rda bir kaydet
            if (i + 1) % 10 == 0 or i == len(lines_to_process) - 1:
                os.makedirs(PARTS_DIR, exist_ok=True)
                with open(output_file, 'w', encoding=file_encoding) as f:
                    f.writelines(translated_lines)
                save_progress(part_num, i + 1, total)
        
        save_progress(part_num, total, total)
        return True
    except Exception as e:
        print(f"Hata ParÃ§a {part_num}: {str(e)}")
        return False

def combine_files(final_output, file_encoding):
    print("\nParÃ§alar birleÅŸtiriliyor...")
    with open(final_output, 'w', encoding=file_encoding) as outfile:
        part_files = sorted([f for f in os.listdir(PARTS_DIR) if f.startswith('part_') and f.endswith('.str')])
        for part_file in part_files:
            with open(os.path.join(PARTS_DIR, part_file), 'r', encoding=file_encoding) as infile:
                outfile.write(infile.read())

def create_directory_structure():
    """Gerekli klasÃ¶r yapÄ±sÄ±nÄ± oluÅŸtur"""
    for directory in [TEMP_DIR, PARTS_DIR, PROGRESS_DIR, STATS_DIR]:
        os.makedirs(directory, exist_ok=True)

def main():
    # KlasÃ¶r yapÄ±sÄ±nÄ± oluÅŸtur
    create_directory_structure()
    
    # Ayarlar
    input_file = "strings_german.str"
    final_output = "translated_output_final.str"
    
    # Sistem kaynaklarÄ±na gÃ¶re optimum iÅŸlem sayÄ±sÄ±nÄ± belirle
    max_processes = get_optimal_process_count()
    
    # Dosya kodlamasÄ±nÄ± tespit et
    file_encoding = detect_encoding(input_file)
    
    # Sistem bilgilerini gÃ¶ster
    print("\nğŸ“Š Sistem Bilgileri:")
    print(f"CPU Ã‡ekirdek SayÄ±sÄ±: {psutil.cpu_count(logical=False)} (Fiziksel)")
    print(f"Toplam Bellek: {psutil.virtual_memory().total / (1024**3):.1f} GB")
    print(f"KullanÄ±labilir Bellek: {psutil.virtual_memory().available / (1024**3):.1f} GB")
    print(f"SeÃ§ilen Paralel Ä°ÅŸlem SayÄ±sÄ±: {max_processes}")
    
    # GÃ¼nlÃ¼k limit bilgisini gÃ¶ster
    stats = TranslationStats()
    remaining_limit = stats.get_remaining_limit()
    print(f"\nğŸ”„ Ã‡eviri Limitleri:")
    print(f"GÃ¼nlÃ¼k Toplam Limit: {DAILY_LIMIT:,} karakter")
    print(f"KullanÄ±lan: {stats.chars_translated:,} karakter")
    print(f"Kalan: {remaining_limit:,} karakter")
    
    # Toplam satÄ±r sayÄ±sÄ±nÄ± bul
    with open(input_file, 'r', encoding=file_encoding) as f:
        total_lines = sum(1 for _ in f)
    
    # Her parÃ§ada olacak satÄ±r sayÄ±sÄ±nÄ± hesapla
    lines_per_part = math.ceil(total_lines / 100)  # 100 parÃ§a
    num_parts = math.ceil(total_lines / lines_per_part)
    
    print(f"\nğŸ“ Ã‡eviri Bilgileri:")
    print(f"Dosya KodlamasÄ±: {file_encoding}")
    print(f"Toplam {total_lines:,} satÄ±r")
    print(f"Her parÃ§a yaklaÅŸÄ±k {lines_per_part:,} satÄ±r iÃ§erecek")
    print(f"Toplam {num_parts} parÃ§a oluÅŸturulacak")
    
    # ParÃ§alarÄ± hazÄ±rla
    tasks = []
    for i in range(num_parts):
        start_line = i * lines_per_part
        end_line = min((i + 1) * lines_per_part, total_lines)
        tasks.append((input_file, i, start_line, end_line, file_encoding))
    
    # Paralel iÅŸleme baÅŸlat
    start_time = datetime.now()
    print("\nğŸš€ Ã‡eviri baÅŸlÄ±yor...")
    
    with multiprocessing.Pool(max_processes) as pool:
        results = []
        for i, task in enumerate(tasks):
            result = pool.apply_async(process_file, task)
            results.append(result)
            
            # Her max_processes kadar gÃ¶rev baÅŸlatÄ±ldÄ±ÄŸÄ±nda veya son gÃ¶revde bekle
            if (i + 1) % max_processes == 0 or i == len(tasks) - 1:
                for r in results:
                    r.wait()
                results = []
    
    # SonuÃ§larÄ± birleÅŸtir
    combine_files(final_output, file_encoding)
    
    # Ä°steÄŸe baÄŸlÄ± temizlik
    clean = input("\nğŸ—‘ï¸ GeÃ§ici dosyalar silinsin mi? (E/H): ").lower()
    if clean == 'e':
        shutil.rmtree(TEMP_DIR)
        print("GeÃ§ici dosyalar temizlendi.")
    else:
        print(f"GeÃ§ici dosyalar '{TEMP_DIR}' klasÃ¶rÃ¼nde saklandÄ±.")
    
    # Son istatistikleri gÃ¶ster
    total_duration = (datetime.now() - start_time).total_seconds()
    stats = TranslationStats()
    print(f"\nâœ¨ Ä°ÅŸlem tamamlandÄ±!")
    print(f"Toplam sÃ¼re: {total_duration/60:.1f} dakika")
    print(f"Ortalama hÄ±z: {total_lines/total_duration:.1f} satÄ±r/saniye")
    print(f"Ã‡evrilen karakter: {stats.chars_translated:,}")
    print(f"Kalan gÃ¼nlÃ¼k limit: {stats.get_remaining_limit():,}")
    print(f"SonuÃ§ dosyasÄ±: {final_output}")

if __name__ == '__main__':
    main() 
